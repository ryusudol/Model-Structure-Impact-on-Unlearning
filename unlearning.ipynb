{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Note: sympy<1.13 is required for torch-cka compatibility\n",
    "!pip install -q timm umap-learn \"sympy<1.13\" torch-cka huggingface_hub\n",
    "\n",
    "print(\"Packages installed.\")\n",
    "print(\"If this is your first run, go to Runtime -> Restart runtime, then run all cells again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path to find utils.py (uploaded to /content/)\n",
    "import sys\n",
    "if '/content' not in sys.path:\n",
    "    sys.path.append('/content')\n",
    "\n",
    "# Verify the file exists\n",
    "import os\n",
    "if not os.path.exists('/content/utils.py'):\n",
    "    print(\"WARNING: Please upload utils.py using the Files tab\")\n",
    "else:\n",
    "    print(\"Setup complete - utils.py found\")\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from typing import Dict\n",
    "\n",
    "from utils import (\n",
    "    get_resnet18, get_vgg16bn, get_data_loaders, get_umap_subset,\n",
    "    create_results_json, save_results, SEED\n",
    ")\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Configuration\n",
    "# ============================================================================\n",
    "\n",
    "FORGET_CLASS = 0        # Class to unlearn (0-9 for CIFAR-10)\n",
    "EPOCHS = 10              # Number of unlearning epochs\n",
    "BATCH_SIZE = 32         # Batch size\n",
    "LEARNING_RATE = 0.0001  # Learning rate\n",
    "MOMENTUM = 0.9          # SGD momentum\n",
    "WEIGHT_DECAY = 5e-4     # Weight decay\n",
    "NUM_CLASSES = 10        # CIFAR-10 classes\n",
    "\n",
    "# Method-specific parameters\n",
    "MAX_GRAD_NORM = 100.0      # Gradient clipping for Gradient Ascent\n",
    "SALIENCY_THRESHOLD = 0.75  # Top 75% weights for SalUn\n",
    "\n",
    "# Device selection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Forget class: {FORGET_CLASS}\")\n",
    "print(f\"Epochs: {EPOCHS}, Batch size: {BATCH_SIZE}, LR: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearning Method Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Method 1: Random Labeling\n",
    "# ============================================================================\n",
    "\n",
    "def random_labeling_unlearn(\n",
    "    model: nn.Module,\n",
    "    retain_loader: DataLoader,\n",
    "    forget_loader: DataLoader,\n",
    "    forget_class: int,\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    device: torch.device,\n",
    "    momentum: float = 0.9,\n",
    "    weight_decay: float = 5e-4\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Random Labeling Unlearning Method.\n",
    "    Combines retain and forget data. For forget class samples,\n",
    "    assigns random labels from remaining classes.\n",
    "    \"\"\"\n",
    "    combined_dataset = ConcatDataset([retain_loader.dataset, forget_loader.dataset])\n",
    "    combined_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    remain_classes = [i for i in range(NUM_CLASSES) if i != forget_class]\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in combined_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Assign random labels to forget class\n",
    "            forget_mask = (labels == forget_class)\n",
    "            if forget_mask.sum() > 0:\n",
    "                random_labels = torch.tensor([\n",
    "                    remain_classes[torch.randint(0, len(remain_classes), (1,)).item()]\n",
    "                    for _ in range(forget_mask.sum())\n",
    "                ], device=device)\n",
    "                labels[forget_mask] = random_labels\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"  Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(combined_loader):.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Method 2: Gradient Ascent\n",
    "# ============================================================================\n",
    "\n",
    "def gradient_ascent_unlearn(\n",
    "    model: nn.Module,\n",
    "    forget_loader: DataLoader,\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    device: torch.device,\n",
    "    max_grad_norm: float = 100.0,\n",
    "    momentum: float = 0.9,\n",
    "    weight_decay: float = 5e-4\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Gradient Ascent Unlearning Method.\n",
    "    Trains ONLY on forget data using NEGATIVE cross-entropy loss.\n",
    "    \"\"\"\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in forget_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = -criterion(outputs, labels)  # NEGATIVE loss\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            running_loss += (-loss.item())\n",
    "        \n",
    "        print(f\"  Epoch [{epoch+1}/{epochs}] Loss: {running_loss/len(forget_loader):.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Method 3: SalUn (Saliency-based Unlearning)\n",
    "# ============================================================================\n",
    "\n",
    "def compute_gradient_saliency(\n",
    "    model: nn.Module,\n",
    "    forget_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    "    threshold: float = 0.75,\n",
    "    max_batches: int = 5\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Compute gradient-based weight saliency mask.\"\"\"\n",
    "    print(\"  Computing gradient-based weight saliency...\")\n",
    "    \n",
    "    gradient_dict = {}\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            gradient_dict[name] = torch.zeros_like(param)\n",
    "    \n",
    "    model.eval()\n",
    "    batch_count = 0\n",
    "    \n",
    "    for inputs, labels in forget_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = -criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad and param.grad is not None:\n",
    "                gradient_dict[name] += param.grad.abs()\n",
    "        \n",
    "        batch_count += 1\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "    \n",
    "    for name in gradient_dict:\n",
    "        gradient_dict[name] /= batch_count\n",
    "    \n",
    "    all_grads = torch.cat([gradient_dict[name].flatten() for name in gradient_dict])\n",
    "    k = int(threshold * len(all_grads))\n",
    "    threshold_value = torch.topk(all_grads, k)[0][-1] if k > 0 else float('inf')\n",
    "    \n",
    "    mask = {name: (gradient_dict[name] >= threshold_value).float().to(device) for name in gradient_dict}\n",
    "    \n",
    "    total_params = sum(m.numel() for m in mask.values())\n",
    "    selected_params = sum(m.sum().item() for m in mask.values())\n",
    "    print(f\"  Saliency mask: {int(selected_params):,}/{total_params:,} params ({selected_params/total_params*100:.1f}%)\")\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def salun_unlearn(\n",
    "    model: nn.Module,\n",
    "    retain_loader: DataLoader,\n",
    "    forget_loader: DataLoader,\n",
    "    forget_class: int,\n",
    "    epochs: int,\n",
    "    lr: float,\n",
    "    device: torch.device,\n",
    "    saliency_threshold: float = 0.75,\n",
    "    grad_clip: float = 100.0,\n",
    "    momentum: float = 0.9,\n",
    "    weight_decay: float = 5e-4\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    SalUn (Saliency-based Unlearning) Method.\n",
    "    Two-phase training with saliency-masked gradient updates.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    remain_classes = [i for i in range(NUM_CLASSES) if i != forget_class]\n",
    "    \n",
    "    saliency_mask = compute_gradient_saliency(model, forget_loader, criterion, device, saliency_threshold)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    \n",
    "    def apply_saliency_mask():\n",
    "        with torch.no_grad():\n",
    "            for name, param in model.named_parameters():\n",
    "                if name in saliency_mask and param.grad is not None:\n",
    "                    param.grad *= saliency_mask[name]\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        total_batches = 0\n",
    "        \n",
    "        # Phase 1: Forget data with random labels\n",
    "        for inputs, labels in forget_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            random_labels = torch.tensor([\n",
    "                remain_classes[torch.randint(0, len(remain_classes), (1,)).item()]\n",
    "                for _ in range(len(labels))\n",
    "            ], device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, random_labels)\n",
    "            loss.backward()\n",
    "            apply_saliency_mask()\n",
    "            if grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        \n",
    "        # Phase 2: Retain data normally\n",
    "        for inputs, labels in retain_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            apply_saliency_mask()\n",
    "            if grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            total_batches += 1\n",
    "        \n",
    "        print(f\"  Epoch [{epoch+1}/{epochs}] Avg Loss: {running_loss/total_batches:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# Method 4: Retrain (on retain data only)\n# ============================================================================\n\ndef retrain_model(\n    model: nn.Module,\n    retain_loader: DataLoader,\n    epochs: int,\n    lr: float,\n    device: torch.device,\n    momentum: float = 0.9,\n    weight_decay: float = 5e-4\n) -> nn.Module:\n    \"\"\"\n    Retrain model on retain data only (excluding forget class).\n    Uses SGD with Nesterov momentum and CosineAnnealingLR scheduler.\n    \"\"\"\n    optimizer = optim.SGD(\n        model.parameters(),\n        lr=lr,\n        momentum=momentum,\n        weight_decay=weight_decay,\n        nesterov=True\n    )\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n        optimizer=optimizer,\n        T_max=epochs\n    )\n    criterion = nn.CrossEntropyLoss()\n\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for inputs, labels in retain_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n        scheduler.step()\n        train_acc = correct / total\n        avg_loss = running_loss / len(retain_loader)\n        current_lr = optimizer.param_groups[0]['lr']\n\n        print(f\"  Epoch [{epoch+1}/{epochs}] Loss: {avg_loss:.4f}, \"\n              f\"Acc: {train_acc:.4f}, LR: {current_lr:.6f}\")\n\n    return model\n\n\ndef save_results_json_only(\n    result: Dict,\n    forget_class: int,\n    output_dir: str = \"backend/data\"\n) -> str:\n    \"\"\"Save only the results JSON (no model weights).\"\"\"\n    import os\n    import json\n    \n    result_id = result.get(\"ID\", \"0000\")\n    output_dir = os.path.abspath(output_dir)\n    class_dir = os.path.join(output_dir, str(forget_class))\n    os.makedirs(class_dir, exist_ok=True)\n\n    json_path = os.path.join(class_dir, f\"{result_id}.json\")\n    with open(json_path, 'w') as f:\n        json.dump(result, f, indent=2, default=float)\n\n    print(f\"Results saved to: {json_path}\")\n    return json_path",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data once for all experiments\n",
    "print(\"Loading CIFAR-10 data...\")\n",
    "train_loader, test_loader, retain_loader, forget_loader, train_set, test_set = \\\n",
    "    get_data_loaders(BATCH_SIZE, FORGET_CLASS)\n",
    "\n",
    "print(\"Preparing UMAP subset...\")\n",
    "umap_subset, umap_loader, selected_indices = get_umap_subset(train_set, test_set)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Train: {len(train_loader.dataset):,}\")\n",
    "print(f\"  Test: {len(test_loader.dataset):,}\")\n",
    "print(f\"  Retain: {len(retain_loader.dataset):,}\")\n",
    "print(f\"  Forget: {len(forget_loader.dataset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Pretrained Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Evaluate Pretrained Model Accuracy\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_accuracy(model, loader, device):\n",
    "    \"\"\"Evaluate model accuracy on a data loader.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = {i: 0 for i in range(NUM_CLASSES)}\n",
    "    class_total = {i: 0 for i in range(NUM_CLASSES)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            for label, pred in zip(labels, predicted):\n",
    "                label = label.item()\n",
    "                class_total[label] += 1\n",
    "                if pred.item() == label:\n",
    "                    class_correct[label] += 1\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    per_class_acc = {i: class_correct[i] / class_total[i] if class_total[i] > 0 else 0.0\n",
    "                     for i in range(NUM_CLASSES)}\n",
    "    \n",
    "    return accuracy, per_class_acc\n",
    "\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRETRAINED MODEL BASELINE EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Evaluate ResNet-18\n",
    "print(\"\\nLoading and evaluating ResNet-18...\")\n",
    "resnet18 = get_resnet18().to(device)\n",
    "\n",
    "train_acc_resnet, train_class_acc_resnet = evaluate_accuracy(resnet18, train_loader, device)\n",
    "test_acc_resnet, test_class_acc_resnet = evaluate_accuracy(resnet18, test_loader, device)\n",
    "\n",
    "print(f\"\\nResNet-18 Results:\")\n",
    "print(f\"  Train Accuracy: {train_acc_resnet*100:.2f}%\")\n",
    "print(f\"  Test Accuracy:  {test_acc_resnet*100:.2f}%\")\n",
    "print(f\"\\n  Per-class Test Accuracy:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"    {name:12s}: {test_class_acc_resnet[i]*100:.2f}%\")\n",
    "\n",
    "del resnet18\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate VGG-16-BN\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Loading and evaluating VGG-16-BN...\")\n",
    "vgg16 = get_vgg16bn().to(device)\n",
    "\n",
    "train_acc_vgg, train_class_acc_vgg = evaluate_accuracy(vgg16, train_loader, device)\n",
    "test_acc_vgg, test_class_acc_vgg = evaluate_accuracy(vgg16, test_loader, device)\n",
    "\n",
    "print(f\"\\nVGG-16-BN Results:\")\n",
    "print(f\"  Train Accuracy: {train_acc_vgg*100:.2f}%\")\n",
    "print(f\"  Test Accuracy:  {test_acc_vgg*100:.2f}%\")\n",
    "print(f\"\\n  Per-class Test Accuracy:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    print(f\"    {name:12s}: {test_class_acc_vgg[i]*100:.2f}%\")\n",
    "\n",
    "del vgg16\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Summary Comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE SUMMARY COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<15} {'Train Acc':>12} {'Test Acc':>12}\")\n",
    "print(\"-\"*40)\n",
    "print(f\"{'ResNet-18':<15} {train_acc_resnet*100:>11.2f}% {test_acc_resnet*100:>11.2f}%\")\n",
    "print(f\"{'VGG-16-BN':<15} {train_acc_vgg*100:>11.2f}% {test_acc_vgg*100:>11.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All Methods on All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and methods\n",
    "models_config = [\n",
    "    (\"ResNet-18\", get_resnet18),\n",
    "    (\"VGG-16-BN\", get_vgg16bn)\n",
    "]\n",
    "\n",
    "methods_config = [\n",
    "    (\"RandomLabeling\", lambda m, rl, fl, fc, e, lr, d: random_labeling_unlearn(\n",
    "        m, rl, fl, fc, e, lr, d, MOMENTUM, WEIGHT_DECAY)),\n",
    "    (\"GradientAscent\", lambda m, rl, fl, fc, e, lr, d: gradient_ascent_unlearn(\n",
    "        m, fl, e, lr, d, MAX_GRAD_NORM, MOMENTUM, WEIGHT_DECAY)),\n",
    "    (\"SalUn\", lambda m, rl, fl, fc, e, lr, d: salun_unlearn(\n",
    "        m, rl, fl, fc, e, lr, d, SALIENCY_THRESHOLD, MAX_GRAD_NORM, MOMENTUM, WEIGHT_DECAY))\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name, model_fn in models_config:\n",
    "    for method_name, method_fn in methods_config:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Running {method_name} on {model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Load fresh pretrained model\n",
    "        print(f\"Loading pretrained {model_name}...\")\n",
    "        model = model_fn().to(device)\n",
    "        original_model = copy.deepcopy(model)\n",
    "        \n",
    "        # Run unlearning\n",
    "        print(f\"Starting {method_name} unlearning...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = method_fn(model, retain_loader, forget_loader, FORGET_CLASS, EPOCHS, LEARNING_RATE, device)\n",
    "        \n",
    "        runtime = time.time() - start_time\n",
    "        print(f\"\\nUnlearning completed in {runtime:.2f} seconds\")\n",
    "        \n",
    "        # Generate results\n",
    "        print(f\"Generating results...\")\n",
    "        result = create_results_json(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            umap_subset=umap_subset,\n",
    "            umap_loader=umap_loader,\n",
    "            selected_indices=selected_indices,\n",
    "            forget_class=FORGET_CLASS,\n",
    "            method_name=method_name,\n",
    "            model_name=model_name,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            runtime=runtime,\n",
    "            device=device,\n",
    "            original_model=original_model\n",
    "        )\n",
    "        \n",
    "        # Save results\n",
    "        save_results(result, model, model_name, FORGET_CLASS, output_dir=\"backend/data\")\n",
    "        all_results.append((model_name, result))\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\n{'-'*40}\")\n",
    "        print(f\"Results for {model_name} + {method_name}:\")\n",
    "        print(f\"  UA: {result['UA']:.3f}  RA: {result['RA']:.3f}\")\n",
    "        print(f\"  TUA: {result['TUA']:.3f}  TRA: {result['TRA']:.3f}\")\n",
    "        print(f\"  FQS: {result['FQS']}  PA: {result['PA']}  Runtime: {result['RTE']:.1f}s\")\n",
    "        print(f\"{'-'*40}\")\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del model, original_model\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Run Retraining on All Models\n\nRetrain models from pretrained weights on retain data only (excluding forget class).",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Run retraining for both models\nretrain_results = []\n\nfor model_name, model_fn in models_config:\n    print(f\"\\n{'='*70}\")\n    print(f\"Running Retrain on {model_name}\")\n    print(f\"{'='*70}\")\n    \n    # Load fresh pretrained model\n    print(f\"Loading pretrained {model_name}...\")\n    model = model_fn().to(device)\n    original_model = copy.deepcopy(model)\n    \n    # Run retraining on retain data only\n    print(f\"Starting retraining (on retain data only)...\")\n    start_time = time.time()\n    \n    model = retrain_model(\n        model=model,\n        retain_loader=retain_loader,\n        epochs=EPOCHS,\n        lr=LEARNING_RATE,\n        device=device,\n        momentum=MOMENTUM,\n        weight_decay=WEIGHT_DECAY\n    )\n    \n    runtime = time.time() - start_time\n    print(f\"\\nRetraining completed in {runtime:.2f} seconds\")\n    \n    # Generate results JSON (same structure as unlearning methods)\n    print(f\"Generating results...\")\n    result = create_results_json(\n        model=model,\n        train_loader=train_loader,\n        test_loader=test_loader,\n        umap_subset=umap_subset,\n        umap_loader=umap_loader,\n        selected_indices=selected_indices,\n        forget_class=FORGET_CLASS,\n        method_name=\"Retrain\",\n        model_name=model_name,\n        epochs=EPOCHS,\n        batch_size=BATCH_SIZE,\n        learning_rate=LEARNING_RATE,\n        runtime=runtime,\n        device=device,\n        original_model=original_model\n    )\n    \n    # Save JSON only (no .pth weights)\n    save_results_json_only(result, FORGET_CLASS, output_dir=\"backend/data\")\n    retrain_results.append((model_name, result))\n    all_results.append((model_name, result))\n    \n    # Print summary\n    print(f\"\\n{'-'*40}\")\n    print(f\"Results for {model_name} + Retrain:\")\n    print(f\"  UA: {result['UA']:.3f}  RA: {result['RA']:.3f}\")\n    print(f\"  TUA: {result['TUA']:.3f}  TRA: {result['TRA']:.3f}\")\n    print(f\"  FQS: {result['FQS']}  PA: {result['PA']}  Runtime: {result['RTE']:.1f}s\")\n    print(f\"{'-'*40}\")\n    \n    # Clean up to free memory\n    del model, original_model\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n\n# Print retrain summary\nprint(\"\\n\" + \"=\"*70)\nprint(\"RETRAINING SUMMARY\")\nprint(\"=\"*70)\nprint(f\"{'Model':<12} {'Method':<16} {'UA':>7} {'RA':>7} {'TUA':>7} {'TRA':>7} {'FQS':>7} {'PA':>7} {'Time':>8}\")\nprint(\"-\"*70)\nfor model_name, r in retrain_results:\n    print(f\"{model_name:<12} {r['Method']:<16} {r['UA']:>7.3f} {r['RA']:>7.3f} {r['TUA']:>7.3f} {r['TRA']:>7.3f} {r['FQS']:>7.4f} {r['PA']:>7.4f} {r['RTE']:>7.1f}s\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive comparison table\n",
    "print(\"\\n\" + \"=\"*95)\n",
    "print(\"COMPARISON: All Unlearning Methods\")\n",
    "print(\"=\"*95)\n",
    "print(f\"{'Model':<12} {'Method':<16} {'UA':>7} {'RA':>7} {'TUA':>7} {'TRA':>7} {'FQS':>7} {'PA':>7} {'Time':>8}\")\n",
    "print(\"-\"*95)\n",
    "\n",
    "for model_name, r in all_results:\n",
    "    print(f\"{model_name:<12} {r['Method']:<16} {r['UA']:>7.3f} {r['RA']:>7.3f} {r['TUA']:>7.3f} {r['TRA']:>7.3f} {r['FQS']:>7.4f} {r['PA']:>7.4f} {r['RTE']:>7.1f}s\")\n",
    "\n",
    "print(\"=\"*95)\n",
    "print(\"\\nMetric Definitions:\")\n",
    "print(\"  UA  = Unlearning Accuracy (accuracy on forget class in training set)\")\n",
    "print(\"  RA  = Remain Accuracy (accuracy on other classes in training set)\")\n",
    "print(\"  TUA = Test Unlearning Accuracy (accuracy on forget class in test set)\")\n",
    "print(\"  TRA = Test Remain Accuracy (accuracy on other classes in test set)\")\n",
    "print(\"  FQS = Forgetting Quality Score (higher = better forgetting)\")\n",
    "print(\"  PA  = Privacy Attack score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by method (average across models)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY BY METHOD (averaged across models)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "methods = [\"RandomLabeling\", \"GradientAscent\", \"SalUn\"]\n",
    "for method in methods:\n",
    "    method_results = [(m, r) for m, r in all_results if r['Method'] == method]\n",
    "    if method_results:\n",
    "        avg_ua = sum(r['UA'] for _, r in method_results) / len(method_results)\n",
    "        avg_ra = sum(r['RA'] for _, r in method_results) / len(method_results)\n",
    "        avg_tua = sum(r['TUA'] for _, r in method_results) / len(method_results)\n",
    "        avg_tra = sum(r['TRA'] for _, r in method_results) / len(method_results)\n",
    "        avg_fqs = sum(r['FQS'] for _, r in method_results) / len(method_results)\n",
    "        avg_pa = sum(r['PA'] for _, r in method_results) / len(method_results)\n",
    "        avg_rte = sum(r['RTE'] for _, r in method_results) / len(method_results)\n",
    "        print(f\"{method:<16}: UA={avg_ua:.3f} RA={avg_ra:.3f} TUA={avg_tua:.3f} TRA={avg_tra:.3f} FQS={avg_fqs:.4f} PA={avg_pa:.4f} Time={avg_rte:.1f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY BY MODEL (averaged across methods)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "models = [\"ResNet-18\", \"VGG-16-BN\"]\n",
    "for model in models:\n",
    "    model_results = [(m, r) for m, r in all_results if m == model]\n",
    "    if model_results:\n",
    "        avg_ua = sum(r['UA'] for _, r in model_results) / len(model_results)\n",
    "        avg_ra = sum(r['RA'] for _, r in model_results) / len(model_results)\n",
    "        avg_tua = sum(r['TUA'] for _, r in model_results) / len(model_results)\n",
    "        avg_tra = sum(r['TRA'] for _, r in model_results) / len(model_results)\n",
    "        avg_fqs = sum(r['FQS'] for _, r in model_results) / len(model_results)\n",
    "        avg_pa = sum(r['PA'] for _, r in model_results) / len(model_results)\n",
    "        avg_rte = sum(r['RTE'] for _, r in model_results) / len(model_results)\n",
    "        print(f\"{model:<12}: UA={avg_ua:.3f} RA={avg_ra:.3f} TUA={avg_tua:.3f} TRA={avg_tra:.3f} FQS={avg_fqs:.4f} PA={avg_pa:.4f} Time={avg_rte:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "### Expected Behavior:\n",
    "- **Lower UA/TUA** = Better forgetting (model no longer recognizes forget class)\n",
    "- **Higher RA/TRA** = Better retention (model still performs well on other classes)\n",
    "- **Higher FQS** = Better overall forgetting quality\n",
    "\n",
    "### Method Characteristics:\n",
    "1. **Random Labeling**: Gentle approach, may not fully forget but preserves retention well\n",
    "2. **Gradient Ascent**: Aggressive forgetting, may harm retention (catastrophic forgetting risk)\n",
    "3. **SalUn**: Balanced approach, targets only relevant weights\n",
    "\n",
    "### Architectural Differences (Research Question):\n",
    "- **ResNet-18**: Skip connections may make forgetting more difficult (information preserved across layers)\n",
    "- **VGG-16**: Sequential architecture may allow more localized forgetting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}